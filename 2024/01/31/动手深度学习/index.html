<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hunter1023.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":3,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="数据操作 + 数据预处理">
<meta property="og:type" content="article">
<meta property="og:title" content="动手深度学习">
<meta property="og:url" content="https://hunter1023.github.io/2024/01/31/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Talk is cheap">
<meta property="og:description" content="数据操作 + 数据预处理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/01/31/xM8PYVEmpXZNUew.png">
<meta property="og:image" content="https://s2.loli.net/2024/01/31/YTJ5M6UlgwsoxyW.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/lu67k1rVAmf2vWM.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/lbD9ATYFWgxmcJC.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/CEPzbewro5X6ZfM.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/VMNnCmqEDyulPz5.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/pkDRx9yAPvJG3VO.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/Vrf8tsUCBW2g69I.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/01/b6RWLasNCx9gGt4.png">
<meta property="og:image" content="https://s2.loli.net/2024/07/16/UBYsV9vqDztk3xZ.png">
<meta property="og:image" content="https://s2.loli.net/2024/07/16/KLzNhOanZp3Ajgq.png">
<meta property="og:image" content="https://s2.loli.net/2024/07/16/9mwMOlINXz682TY.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/iEPT1mbDvFRY6jf.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/02/S4ibvxmUyFD1ewc.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/02/tq1AQepcDlT6Cnj.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/yTbtqaE15kHp89s.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/6G9MnazxBkQhlUR.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/zwVkSyEMOnpJI6t.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/uzqFg3CbdOxWGtS.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/9nlzW3XjQTbDoFV.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/2EkFILYvm5VKhTs.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/iFOU5G2j9Iq3XoC.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/z3JOEnvTGb5WgtD.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/UaxWfE9ClgcXQ7S.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/KoyqupRtHLO41cQ.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/natWsYGF1XMl72m.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/03/H8sMuNCBxZ5mGDf.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/04/NgqvciKtPxzBV9b.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/04/NWZPRcvf5VzF6Iw.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/04/BQTDY8OuV4xiIAZ.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/04/WopnehrGsI71uEY.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/04/yeBZORxfaDw8cCi.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/22/QPhN9cY6Gg2yufK.png">
<meta property="og:image" content="https://s2.loli.net/2024/02/23/6kwuFPxZlWJeQT5.png">
<meta property="article:published_time" content="2024-01-31T07:35:26.000Z">
<meta property="article:modified_time" content="2024-08-08T13:01:50.000Z">
<meta property="article:author" content="Hunter">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/01/31/xM8PYVEmpXZNUew.png">


<link rel="canonical" href="https://hunter1023.github.io/2024/01/31/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://hunter1023.github.io/2024/01/31/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","path":"2024/01/31/动手深度学习/","title":"动手深度学习"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>动手深度学习 | Talk is cheap</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Talk is cheap</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">数据操作 + 数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#N%E7%BB%B4%E6%95%B0%E7%BB%84"><span class="nav-number">1.1.</span> <span class="nav-text">N维数组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C"><span class="nav-number">1.2.</span> <span class="nav-text">数据操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.3.</span> <span class="nav-text">数据预处理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"><span class="nav-number">2.</span> <span class="nav-text">线性代数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%87%E9%87%8F"><span class="nav-number">2.1.</span> <span class="nav-text">标量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F"><span class="nav-number">2.2.</span> <span class="nav-text">向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5"><span class="nav-number">2.3.</span> <span class="nav-text">矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E6%AE%8A%E7%9F%A9%E9%98%B5"><span class="nav-number">2.3.1.</span> <span class="nav-text">特殊矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%BE%E4%BE%8B"><span class="nav-number">2.3.2.</span> <span class="nav-text">代码举例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF-odot"><span class="nav-number">2.3.3.</span> <span class="nav-text">哈达玛积 $\odot$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%89%E6%8C%87%E5%AE%9A%E8%BD%B4%E6%B1%82%E5%92%8C"><span class="nav-number">2.3.4.</span> <span class="nav-text">按指定轴求和</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B3%E5%9D%87%E5%80%BC"><span class="nav-number">2.3.5.</span> <span class="nav-text">平均值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%80%BB%E5%92%8C%E6%88%96%E5%9D%87%E5%80%BC%E6%97%B6-%E4%BF%9D%E6%8C%81%E8%BD%B4%E6%95%B0%E4%B8%8D%E5%8F%98"><span class="nav-number">2.3.6.</span> <span class="nav-text">计算总和或均值时 保持轴数不变</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF-cdot-%EF%BC%88%E7%82%B9%E4%B9%98%E3%80%81%E5%86%85%E7%A7%AF%EF%BC%89"><span class="nav-number">2.3.7.</span> <span class="nav-text">点积 $\cdot$ （点乘、内积）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%E7%A7%AF"><span class="nav-number">2.3.8.</span> <span class="nav-text">矩阵向量积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-number">2.3.9.</span> <span class="nav-text">矩阵乘法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6"><span class="nav-number">2.3.10.</span> <span class="nav-text">梯度</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC"><span class="nav-number">3.</span> <span class="nav-text">自动求导</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E5%87%BD%E6%95%B0-y-2x-Tx-%E5%85%B3%E4%BA%8E%E5%88%97%E5%90%91%E9%87%8Fx%E6%B1%82%E5%AF%BC"><span class="nav-number">3.1.</span> <span class="nav-text">对函数$y &#x3D; 2x^Tx$ 关于列向量x求导</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%8D%E6%96%B0%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6%E6%97%B6%EF%BC%8C%E8%A6%81%E6%B8%85%E9%99%A4%E4%B9%8B%E5%89%8D%E7%9A%84%E5%80%BC"><span class="nav-number">3.2.</span> <span class="nav-text">重新计算梯度时，要清除之前的值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%86%E6%9F%90%E4%BA%9B%E8%AE%A1%E7%AE%97%E7%A7%BB%E5%8A%A8%E5%88%B0%E8%AE%B0%E5%BD%95%E7%9A%84%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B9%8B%E5%A4%96"><span class="nav-number">3.3.</span> <span class="nav-text">将某些计算移动到记录的计算图之外</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B3%E4%BD%BF%E6%9E%84%E5%BB%BA%E5%87%BD%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97%E5%9B%BE%E9%9C%80%E8%A6%81%E9%80%9A%E8%BF%87Python%E6%8E%A7%E5%88%B6%E6%B5%81%EF%BC%8C%E4%BB%8D%E7%84%B6%E5%8F%AF%E4%BB%A5%E8%AE%A1%E7%AE%97%E5%BE%97%E5%88%B0%E5%8F%98%E9%87%8F%E7%9A%84%E6%A2%AF%E5%BA%A6"><span class="nav-number">3.4.</span> <span class="nav-text">即使构建函数的计算图需要通过Python控制流，仍然可以计算得到变量的梯度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">线性回归 + 基础优化算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.</span> <span class="nav-text">线性回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A1%E9%87%8F%E9%A2%84%E4%BC%B0%E8%B4%A8%E9%87%8F"><span class="nav-number">4.1.1.</span> <span class="nav-text">衡量预估质量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.1.2.</span> <span class="nav-text">参数学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">基础优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">4.2.1.</span> <span class="nav-text">梯度下降</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch%E5%AE%9E%E7%8E%B0"><span class="nav-number">4.3.</span> <span class="nav-text">pytorch实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B0%83%E7%94%A8%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%8E%B0%E6%9C%89%E7%9A%84api%E6%9D%A5%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.3.1.</span> <span class="nav-text">调用框架中现有的api来读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%E7%9A%84%E9%A2%84%E5%AE%9A%E4%B9%89%E5%A5%BD%E7%9A%84%E5%B1%82"><span class="nav-number">4.3.2.</span> <span class="nav-text">使用框架的预定义好的层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="nav-number">4.3.3.</span> <span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E4%BD%BF%E7%94%A8MSELoss%E7%B1%BB"><span class="nav-number">4.3.4.</span> <span class="nav-text">计算均方误差使用MSELoss类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%8C%96SGD%E5%AE%9E%E4%BE%8B"><span class="nav-number">4.3.5.</span> <span class="nav-text">实例化SGD实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">4.3.6.</span> <span class="nav-text">训练</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Softmax%E5%9B%9E%E5%BD%92"><span class="nav-number">5.</span> <span class="nav-text">Softmax回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Softmax%E5%87%BD%E6%95%B0"><span class="nav-number">5.1.</span> <span class="nav-text">Softmax函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="nav-number">5.2.</span> <span class="nav-text">交叉熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.3.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9D%87%E6%96%B9%E6%8D%9F%E5%A4%B1-L-2-Loss"><span class="nav-number">5.3.1.</span> <span class="nav-text">均方损失 $L_2$ Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%9D%E5%AF%B9%E5%80%BC%E6%8D%9F%E5%A4%B1-L-1-Loss"><span class="nav-number">5.3.2.</span> <span class="nav-text">绝对值损失 $L_1$ Loss</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.4.</span> <span class="nav-text">Softmax回归的从零开始实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0Softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.4.1.</span> <span class="nav-text">实现Softmax回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.4.2.</span> <span class="nav-text">实现交叉熵损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%86%E9%A2%84%E6%B5%8B%E7%B1%BB%E5%88%AB%E4%B8%8E%E7%9C%9F%E5%AE%9Ey%E5%85%83%E7%B4%A0%E8%BF%9B%E8%A1%8C%E6%AF%94%E8%BE%83"><span class="nav-number">5.4.3.</span> <span class="nav-text">将预测类别与真实y元素进行比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E5%87%86%E7%A1%AE%E7%8E%87"><span class="nav-number">5.4.4.</span> <span class="nav-text">评估准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%80%E4%B8%AA%E8%BF%AD%E4%BB%A3%E5%91%A8%E6%9C%9F"><span class="nav-number">5.4.5.</span> <span class="nav-text">训练的一个迭代周期</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%9C%A8%E5%8A%A8%E7%94%BB%E4%B8%AD%E7%BB%98%E5%88%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB"><span class="nav-number">5.4.6.</span> <span class="nav-text">定义一个在动画中绘制数据的类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%87%BD%E6%95%B0"><span class="nav-number">5.4.7.</span> <span class="nav-text">训练函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.4.8.</span> <span class="nav-text">小批量随机梯度下降来优化模型的损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%8310%E4%B8%AA%E8%BF%AD%E4%BB%A3%E5%91%A8%E6%9C%9F%EF%BC%8C%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B"><span class="nav-number">5.4.9.</span> <span class="nav-text">训练10个迭代周期，对图像进行分类预测</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">6.</span> <span class="nav-text">多层感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">6.1.</span> <span class="nav-text">感知机</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">7.</span> <span class="nav-text">模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%AE%B9%E9%87%8F"><span class="nav-number">7.1.</span> <span class="nav-text">模型容量</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C-NiN"><span class="nav-number">8.</span> <span class="nav-text">网络中的网络 NiN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">8.1.</span> <span class="nav-text">全连接层的问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NiN%E5%9D%97"><span class="nav-number">8.2.</span> <span class="nav-text">NiN块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NiN%E6%9E%B6%E6%9E%84"><span class="nav-number">8.3.</span> <span class="nav-text">NiN架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-GoogLeNet-Inception-V3"><span class="nav-number">9.</span> <span class="nav-text">含并行连结的网络 GoogLeNet &#x2F; Inception V3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">10.</span> <span class="nav-text">批量归一化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82"><span class="nav-number">10.1.</span> <span class="nav-text">批量归一化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%9C%A8%E5%81%9A%E4%BB%80%E4%B9%88"><span class="nav-number">10.2.</span> <span class="nav-text">批量归一化在做什么</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C-ResNet"><span class="nav-number">11.</span> <span class="nav-text">残差网络 ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E5%9D%97"><span class="nav-number">11.1.</span> <span class="nav-text">残差块</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF"><span class="nav-number">12.</span> <span class="nav-text">数据增广</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83"><span class="nav-number">13.</span> <span class="nav-text">微调</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="nav-number">14.</span> <span class="nav-text">序列模型</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hunter</p>
  <div class="site-description" itemprop="description">Tough times never last, but tough people do.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">98</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">175</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hunter1023.github.io/2024/01/31/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hunter">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Talk is cheap">
      <meta itemprop="description" content="Tough times never last, but tough people do.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="动手深度学习 | Talk is cheap">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          动手深度学习<a href="https://github.com/Hunter1023/hexo_blog/edit/gh-pages/source/_posts/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-01-31 15:35:26" itemprop="dateCreated datePublished" datetime="2024-01-31T15:35:26+08:00">2024-01-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-08 21:01:50" itemprop="dateModified" datetime="2024-08-08T21:01:50+08:00">2024-08-08</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="数据操作-数据预处理"><a href="#数据操作-数据预处理" class="headerlink" title="数据操作 + 数据预处理"></a>数据操作 + 数据预处理</h1><span id="more"></span>

<h2 id="N维数组"><a href="#N维数组" class="headerlink" title="N维数组"></a>N维数组</h2><p>N维数组是机器学习和神经网络的主要数据结构。</p>
<ol>
<li><p>0维 标量</p>
<blockquote>
<p>1.0</p>
</blockquote>
<p> 表示一个类别</p>
</li>
<li><p>维 向量</p>
<blockquote>
<p>[1.0, 2.7, 3.4]</p>
</blockquote>
<p> 表示一个特征向量</p>
</li>
<li><p>2维 矩阵</p>
<blockquote>
<p>[[1.0, 2.7, 3.4]</p>
<p>[5.0, 0.2, 4.6]</p>
<p>[4.3, 8.5, 0.2]]</p>
</blockquote>
<p> 表示一个样本—特征矩阵</p>
</li>
<li><p>3维</p>
<blockquote>
<p>[ [ [0.1, 2.7, 3.4]</p>
<p>​      [5.0, 0.2, 4.6]</p>
<p>​      [4.3, 8.5, 0.2] ]</p>
<p> [ [3.2, 5.7, 3.4]</p>
<p>   [5.4, 6.2, 3.2]</p>
<p>   [4.1, 3.5, 6.2] ]  ]</p>
</blockquote>
<p> 如RGB图片（w * H * channels )</p>
</li>
<li><p>4维</p>
<p> 一个RGB图片的批量 （批量大小 * 宽 * 高 * 通道）</p>
</li>
<li><p>5维</p>
<p> 一个视频批量 （批量大小 * 时间 * 宽 * 高 * 通道）</p>
</li>
</ol>
<hr>
<h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>张量（tensor）<strong>表示一个</strong>数值组成的数组</strong>，这个数据可能有多个维度。</p>
<ul>
<li><code>shape</code>属性：访问张量的形状。</li>
<li><code>numel()</code>函数：访问张量中元素的总数。</li>
<li><code>reshape()</code>函数：改变张量的形状而不改变元素数量和元素值。</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>shape
x<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/01/31/xM8PYVEmpXZNUew.png" alt="reshape()"></p>
<hr>
<ul>
<li><code>torch.zeros()</code> 使用全0填充<strong>指定形状</strong>的张量</li>
<li><code>torch.ones()</code> 使用全1填充<strong>指定形状</strong>的张量</li>
<li><code>torch.tensor()</code> 为张量中的每个元素赋予确定值</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span>， <span class="token number">3</span>， <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li><p>常见的标准运算符（<code>+</code>、<code>-</code>、<code>*</code>、<code>/</code>和求幂<code>**</code>）都可以被升级为<strong>按元素运算</strong>。</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">+</span> y<span class="token punctuation">,</span> x <span class="token operator">-</span> y<span class="token punctuation">,</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> x <span class="token operator">/</span> y<span class="token punctuation">,</span> x<span class="token operator">**</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/01/31/YTJ5M6UlgwsoxyW.png" alt="image-20240131222451661"></p>
</li>
</ul>
<hr>
<ul>
<li><p><code>torch.cat()</code> 连结张量</p>
<p>  <img src="https://s2.loli.net/2024/02/01/lu67k1rVAmf2vWM.png" alt="image-20240201160930619"></p>
</li>
</ul>
<hr>
<ul>
<li><p>通过逻辑运算符构建二元张量</p>
<p>  <img src="https://s2.loli.net/2024/02/01/lbD9ATYFWgxmcJC.png" alt="image-20240201161036811"></p>
</li>
</ul>
<hr>
<ul>
<li><p><code>x.sum()</code> 对张量中所有元素进行求和，会产生<strong>只有一个元素的张量</strong>。</p>
</li>
<li><p>即使形状不同，仍然可以通过调用<strong>广播机制</strong>（<strong>维度的尺寸要么相等，要么其中一个维度为1</strong>）来执行按元素操作。</p>
<p>  <img src="https://s2.loli.net/2024/02/01/CEPzbewro5X6ZfM.png" alt="image-20240201162656769"></p>
</li>
</ul>
<hr>
<ul>
<li><p>可以用<code>[-1]</code>选择最后一个元素</p>
</li>
<li><p>可以用<code>[1:3]</code>选择第二个和第三个元素</p>
</li>
<li><p>可以指定索引将元素写入矩阵</p>
<p>  <img src="https://s2.loli.net/2024/02/01/VMNnCmqEDyulPz5.png" alt="image-20240201163611717"></p>
</li>
<li><p><strong>为多个元素赋值相同的元素</strong>，只需要<strong>索引所有元素</strong>，为其赋值。</p>
<p>  <img src="https://s2.loli.net/2024/02/01/pkDRx9yAPvJG3VO.png" alt="image-20240201163810436"></p>
</li>
</ul>
<hr>
<ul>
<li><p>将<strong>Numpy类型</strong>的张量转换为<strong>pytorch类型</strong>的张量</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> X<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li><p>将大小为1的张量<strong>转换为Python标量</strong></p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ul>
<hr>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><ol>
<li><p>创建人工数据集，并存储在csv文件</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token comment"># 创建 ../data文件夹</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># CSV 文件的路径 ../data/house_tiny.csv</span>
data_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'house_tiny.csv'</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NumRooms,Alley,Price\n'</span><span class="token punctuation">)</span> <span class="token comment"># 列名</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,Pave,127500\n'</span><span class="token punctuation">)</span> <span class="token comment"># 每行表示一个数据样本</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'2,NA,106000\n'</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'4,NA,178100\n'</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,NA,140000\n'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>从csv文件中加载</strong>原始数据集</p>
<p> <img src="https://s2.loli.net/2024/02/01/Vrf8tsUCBW2g69I.png" alt="image-20240201213545427"></p>
</li>
<li><p>为了处理<strong>缺失的数据</strong>，典型的方法包括<strong>插值</strong>和<strong>删除</strong>。</p>
<p> 下例通过插入数值，消除缺失的数值。</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
<span class="token comment"># 用 非空数据的平均值 填充NaN</span>
inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>numeric_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p> <img src="https://s2.loli.net/2024/02/01/b6RWLasNCx9gGt4.png" alt="image-20240201224423732"></p>
</li>
<li><p>对于类别值或离散值，将<code>NaN</code>视为一个类别。</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 独热编码（将分类变量转换为二进制向量）</span>
<span class="token comment"># 每个分类变量的每个可能取值都被编码为一个二进制特征</span>
<span class="token comment"># 当分类变量有多个不同取值时，会生成更多的列。这可能会导致维度灾难（curse of dimensionality）的问题</span>
inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># 将inputs中的所有值转换为数值类型（True/False --> 1/0）</span>
inputs <span class="token operator">*=</span> <span class="token number">1</span>
inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p> <img src="https://s2.loli.net/2024/07/16/UBYsV9vqDztk3xZ.png" alt="image-20240201234546437"></p>
</li>
<li><p>将dataframe转换为张量</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

<span class="token comment"># 把所有条目都是数值类型的 dataframe格式的inputs和outputs</span>
<span class="token comment"># 转换为张量格式</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

X<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p> <img src="https://s2.loli.net/2024/07/16/KLzNhOanZp3Ajgq.png" alt="image-20240201235240914"></p>
</li>
</ol>
<hr>
<h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><h2 id="标量"><a href="#标量" class="headerlink" title="标量"></a>标量</h2><ul>
<li>简单操作<ul>
<li>$c &#x3D; a + b$</li>
<li>$c &#x3D; a \cdot b$</li>
<li>$c &#x3D; \sin a$</li>
</ul>
</li>
<li>长度<ul>
<li>$|a|&#x3D;\begin{cases} a, &amp; \text{if } a &gt; 0 \ -a, &amp; \text{if } x \leq 0 \end{cases}$</li>
<li>$|a+b| \leq |a| + |b|$</li>
<li>$|a\cdot b|&#x3D;|a| \cdot |b|$</li>
</ul>
</li>
</ul>
<p>标量由<strong>只有一个元素的张量</strong>表示。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

x <span class="token operator">+</span> y<span class="token punctuation">,</span> x <span class="token operator">-</span> y<span class="token punctuation">,</span> x <span class="token operator">*</span> y<span class="token punctuation">,</span> x <span class="token operator">/</span> y<span class="token punctuation">,</span> x<span class="token operator">**</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><ul>
<li><p>简单操作</p>
<ul>
<li>$c &#x3D; a + b \text{ where } c_i &#x3D; a_i + b_i$</li>
<li>$c &#x3D; \alpha \cdot b \text{ where } c_i &#x3D; \alpha b_i$ （<strong>α是标量</strong>）</li>
<li>$c &#x3D; \sin a \text{ where } c_i &#x3D; \sin a_i$</li>
</ul>
</li>
<li><p>长度</p>
<ul>
<li>$||a||<em>2&#x3D;\sqrt{\sum\limits</em>{i&#x3D;1}^ma_i^2}$</li>
<li>$||a||\geq 0 \text{ for all } a$</li>
<li>$||a+b|| \leq ||a|| + ||b||$</li>
<li>$||\alpha\cdot b||&#x3D;|\alpha| \cdot ||b||$ （<strong>α是标量</strong>）</li>
</ul>
</li>
<li><p>点乘</p>
<p>  $a^Tb &#x3D; \sum\limits_ia_ib_i$</p>
<p>  如果a与b<strong>正交</strong>，则$a^Tb &#x3D; 0$</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 可以把向量视为标量值组成的列表</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># 张量的长度</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment"># 只有一个轴的张量，形状只有一个元素。 </span>
x<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><ul>
<li><p>简单操作</p>
<ul>
<li>$C &#x3D; A + B \text{ where }C_{ij}&#x3D;A_{ij}+B_{ij}$</li>
<li>$C&#x3D;\alpha\cdot B \text{ where } C_{ij}&#x3D;\alpha B_{ij}$</li>
<li>$C&#x3D;\sin A \text{ where } C_{ij} &#x3D; \sin A_{ij}$</li>
</ul>
</li>
<li><p>乘法（矩阵 x <strong>向量</strong>）</p>
<p>   $C &#x3D; Ab \text{ where } C_i&#x3D;\sum\limits_jA_{ij}b_j$ （矩阵A的<strong>每一行</strong>和向量b做内积）</p>
<p>  <img src="https://s2.loli.net/2024/07/16/9mwMOlINXz682TY.png" alt="image-20240202081512116"></p>
</li>
<li><p>乘法（矩阵 x 矩阵）</p>
<p>  $C &#x3D; AB \text{ where } C_{ik}&#x3D;\sum\limits_jA_{ij}B_{jk}$</p>
</li>
<li><p>范数（norm）</p>
<p>  <strong>F范数</strong>：把<strong>所有元素</strong>的模取平方和，再开方。</p>
<p>  $||A||<em>2&#x3D;\sqrt{|A</em>{11}|^2+… + |A_{nn}|^2}&#x3D;\sqrt{\sum\limits_{i,j}|a_{ij}|^2}$</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/02/03/iEPT1mbDvFRY6jf.png" alt="image-20240203005800817"></p>
<p>  平方范数$L_2$，</p>
</li>
</ul>
<hr>
<h3 id="特殊矩阵"><a href="#特殊矩阵" class="headerlink" title="特殊矩阵"></a>特殊矩阵</h3><ul>
<li><p>对称和反对称矩阵</p>
<ul>
<li>$A_{ij}&#x3D;A_{ji}$</li>
<li>$A_{ij}&#x3D;-A_{ji}$</li>
</ul>
</li>
<li><p><strong>正定</strong>矩阵</p>
<p>  $x$为任意<strong>向量</strong>，$x^TAx \geq 0$ ，就称A为正定矩阵。</p>
</li>
<li><p><strong>正交</strong>矩阵</p>
<ul>
<li>所有<strong>行&#x2F;列</strong>都是<strong>单位向量</strong>，且<strong>两两正交</strong></li>
<li>可以写成$AA^T&#x3D;E$ （对角线全为1的单位矩阵）</li>
</ul>
</li>
<li><p><strong>置换</strong>矩阵</p>
</li>
</ul>
<hr>
<ul>
<li><p>特征向量</p>
<p>  <strong>不被矩阵改变方向</strong>的向量，称为特征向量。<strong>对称矩阵</strong>总能找到特征向量。</p>
<p>  $Ax &#x3D; \lambda x$</p>
</li>
</ul>
<hr>
<h3 id="代码举例"><a href="#代码举例" class="headerlink" title="代码举例"></a>代码举例</h3><p>通过指定两个分量$m$和$n$来创建一个形状为$m\times n$的矩阵。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># 得到矩阵的转置</span>
A<span class="token punctuation">.</span>T<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="哈达玛积-odot"><a href="#哈达玛积-odot" class="headerlink" title="哈达玛积 $\odot$"></a>哈达玛积 $\odot$</h3><p>两个矩阵的<strong>按元素乘法</strong>称为哈达玛积$\odot$，不常用。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># 通过分配新内存，将A的一个副本分配给B</span>
B <span class="token operator">=</span> A<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>

A <span class="token operator">*</span> B<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/02/S4ibvxmUyFD1ewc.png" alt="image-20240202224121178"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token number">2</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
a <span class="token operator">+</span> X<span class="token punctuation">,</span> <span class="token punctuation">(</span>a <span class="token operator">*</span> X<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/02/tq1AQepcDlT6Cnj.png" alt="image-20240202224400195"></p>
<hr>
<h3 id="按指定轴求和"><a href="#按指定轴求和" class="headerlink" title="按指定轴求和"></a>按指定轴求和</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/03/yTbtqaE15kHp89s.png" alt="image-20240203000156266"></p>
<ul>
<li><p>针对第1个维度求和</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">A_sum_axis0 <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> A_sum_axis0<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> A_sum_axis0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/02/03/6G9MnazxBkQhlUR.png" alt="image-20240203000257268"></p>
</li>
<li><p>针对第2个维度求和</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">A_sum_axis1 <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> A_sum_axis1<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> A_sum_axis1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/02/03/zwVkSyEMOnpJI6t.png" alt="image-20240203000435931"></p>
</li>
<li><p>针对1、2<strong>两个维度</strong>求和</p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/02/03/uzqFg3CbdOxWGtS.png" alt="image-20240203000524694"></p>
</li>
<li><p>针对第1个维度计算<strong>累加和</strong></p>
  <pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>  <img src="https://s2.loli.net/2024/02/03/9nlzW3XjQTbDoFV.png" alt="image-20240203003928627"></p>
</li>
</ul>
<hr>
<h3 id="平均值"><a href="#平均值" class="headerlink" title="平均值"></a>平均值</h3><ul>
<li><code>A.mean()</code></li>
<li><code>A.mean(axis=0)</code></li>
</ul>
<hr>
<h3 id="计算总和或均值时-保持轴数不变"><a href="#计算总和或均值时-保持轴数不变" class="headerlink" title="计算总和或均值时 保持轴数不变"></a>计算总和或均值时 保持轴数不变</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span> <span class="token operator">*</span> <span class="token number">2.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># 保持第2维的存在（只有1行），对于广播机制是一个很好的操作</span>
A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/03/2EkFILYvm5VKhTs.png" alt="image-20240203003249355"></p>
<hr>
<h3 id="点积-cdot-（点乘、内积）"><a href="#点积-cdot-（点乘、内积）" class="headerlink" title="点积 $\cdot$ （点乘、内积）"></a>点积 $\cdot$ （点乘、内积）</h3><p>点积是相同位置的按元素乘积的<strong>和</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4.</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/03/iFOU5G2j9Iq3XoC.png" alt="image-20240203004516282"></p>
<p>可以通过执行按<strong>元素乘法</strong>（哈达玛积$\odot$），然后<strong>求和</strong>来表示两个向量的点积。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x <span class="token operator">*</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<h3 id="矩阵向量积"><a href="#矩阵向量积" class="headerlink" title="矩阵向量积"></a>矩阵向量积</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>A<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/03/z3JOEnvTGb5WgtD.png" alt="image-20240203005305511"></p>
<hr>
<h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">B <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/03/UaxWfE9ClgcXQ7S.png" alt="image-20240203005453450"></p>
<hr>
<h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>梯度是导数<strong>在向量上的拓展</strong>，指向<strong>值变化最大的方向</strong>。</p>
<ol>
<li><p>y是标量，x是向量</p>
<p> <img src="https://s2.loli.net/2024/02/03/KoyqupRtHLO41cQ.png" alt="image-20240203010527048"></p>
<p> x是列向量，求导之后，会变成<strong>行向量</strong>。</p>
<p> <img src="https://s2.loli.net/2024/02/03/natWsYGF1XMl72m.png" alt="image-20240203010607386"></p>
<p> <img src="https://s2.loli.net/2024/02/03/H8sMuNCBxZ5mGDf.png" alt="image-20240203010856496"></p>
</li>
<li><p>y是向量，x是标量</p>
<p> <img src="https://s2.loli.net/2024/02/04/NgqvciKtPxzBV9b.png" alt="image-20240204155019314"></p>
<p> y是列向量，求导之后，还是<strong>列向量</strong>。</p>
<p> <img src="https://s2.loli.net/2024/02/04/NWZPRcvf5VzF6Iw.png" alt="image-20240204155124157"></p>
</li>
<li><p>y和x<strong>都是向量</strong></p>
<p> 求导之后，是一个<strong>矩阵</strong>。</p>
<p> <img src="https://s2.loli.net/2024/02/04/BQTDY8OuV4xiIAZ.png" alt="image-20240204155431906"></p>
</li>
</ol>
<hr>
<h1 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h1><p>自动求导计算<strong>一个函数在指定值上的导数</strong>。自动求导有两种模式：</p>
<ol>
<li><p>正向累积</p>
<p> $\frac{\partial y}{\partial x}&#x3D;\frac{\partial y}{\partial u_n}(\frac{\partial u_n}{\partial u_{n-1}}(\dots(\frac{\partial u_2}{\partial u_1}\frac{\partial u_1}{\partial x})))$</p>
</li>
<li><p><strong>反向累积（反向传递）</strong></p>
<p> $\frac{\partial y}{\partial x}&#x3D;(((\frac{\partial y}{\partial u_n}\frac{\partial u_n}{\partial u_{n-1}})\dots)\frac{\partial u_2}{\partial u_1})\frac{\partial u_1}{\partial x}$</p>
</li>
</ol>
<p>反向累积求导的<strong>复杂度</strong></p>
<ul>
<li><p>时间复杂度 $O(n)$，n是操作子个数</p>
<p>  通常和正向累积代价类似。</p>
</li>
<li><p>空间复杂度$O(n)$</p>
<p>  需要存储<strong>正向计算的所有中间结果</strong>。正向累积的空间复杂度是$O(1)$</p>
</li>
</ul>
<hr>
<h2 id="对函数-y-2x-Tx-关于列向量x求导"><a href="#对函数-y-2x-Tx-关于列向量x求导" class="headerlink" title="对函数$y &#x3D; 2x^Tx$ 关于列向量x求导"></a>对函数$y &#x3D; 2x^Tx$ 关于列向量x求导</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4.</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
x<span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad <span class="token comment"># 默认值是None</span>

y <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span>

<span class="token comment"># 通过调用反向传播函数，自动计算y关于x每个分量的梯度。</span>
<span class="token comment"># 执行backward前，y必须是个标量</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h2 id="重新计算梯度时，要清除之前的值"><a href="#重新计算梯度时，要清除之前的值" class="headerlink" title="重新计算梯度时，要清除之前的值"></a>重新计算梯度时，要清除之前的值</h2><p>如继续对函数$y &#x3D; \sum\limits_{i&#x3D;1}^nx_i$关于列向量x求导。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 默认情况下，pytorch会累积梯度，需要清除之前的值</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># y = x_1 + x_2 + ... + x_n</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h2 id="将某些计算移动到记录的计算图之外"><a href="#将某些计算移动到记录的计算图之外" class="headerlink" title="将某些计算移动到记录的计算图之外"></a>将某些计算移动到记录的计算图之外</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x <span class="token operator">*</span> x
<span class="token comment"># 使u不是一个关于x的函数，而是看做一个常数</span>
u <span class="token operator">=</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 会被看做 常数 * x</span>
z <span class="token operator">=</span> u <span class="token operator">*</span> x

z<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/04/WopnehrGsI71uEY.png" alt="image-20240204192352450"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://s2.loli.net/2024/02/04/yeBZORxfaDw8cCi.png" alt="image-20240204192422844"></p>
<hr>
<h2 id="即使构建函数的计算图需要通过Python控制流，仍然可以计算得到变量的梯度"><a href="#即使构建函数的计算图需要通过Python控制流，仍然可以计算得到变量的梯度" class="headerlink" title="即使构建函数的计算图需要通过Python控制流，仍然可以计算得到变量的梯度"></a>即使构建函数的计算图需要通过Python控制流，仍然可以计算得到变量的梯度</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>
    b <span class="token operator">=</span> a <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token comment"># F范数：把所有元素的模取平方和，再开方。</span>
    <span class="token keyword">while</span> b<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1000</span><span class="token punctuation">:</span>
        b <span class="token operator">=</span> b <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token keyword">if</span> b<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        c <span class="token operator">=</span> b
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        c <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> b
    <span class="token keyword">return</span> c

<span class="token comment"># 随机数，size为空，即标量</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
d <span class="token operator">=</span> f<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
d<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

a<span class="token punctuation">.</span>grad <span class="token operator">==</span> d <span class="token operator">/</span> a<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h1 id="线性回归-基础优化算法"><a href="#线性回归-基础优化算法" class="headerlink" title="线性回归 + 基础优化算法"></a>线性回归 + 基础优化算法</h1><h2 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h2><ul>
<li><p>给定<strong>n维</strong>输入$\mathbf{x} &#x3D; [x_1, x_2, \dots, x_n]^T$</p>
</li>
<li><p>线性回归模型有一个<strong>n维权重$\mathbf{w}$<strong>和一个</strong>标量偏差b</strong></p>
<p>  $\mathbf{w}&#x3D;[w_1, w_2, \dots, w_n]^T, \ b$</p>
</li>
<li><p>输出是<strong>输入的加权和</strong></p>
<p>  $y &#x3D; w_1x_1 +w_2x_2 +\dots+w_nx_n+b$</p>
<p>  向量版本：$y&#x3D;\langle\mathbf{w},\mathbf{x}\rangle+b$</p>
</li>
</ul>
<p>线性回归模型可以看做<strong>单层神经网络</strong>，有显式解。</p>
<hr>
<h3 id="衡量预估质量"><a href="#衡量预估质量" class="headerlink" title="衡量预估质量"></a>衡量预估质量</h3><p>使用**平方损失（均方损失）**衡量预测值和真实值的差异。</p>
<p>$\mathscr{l}(y,\hat{y})&#x3D;\frac{1}{2}(y-\hat{y})^2$ 		($\frac{1}{2}$是为了求导时，方便消去)</p>
<hr>
<h3 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h3><ul>
<li><p>训练损失</p>
<p>  $\ell(\mathbf{X},\mathbf{y},\mathbf{w},b)&#x3D;\frac{1}{2n}\sum\limits_{i&#x3D;1}^{n}(y_i-\langle\mathbf{x}_i,\mathbf{w}\rangle-b)^2$</p>
</li>
<li><p>通过<strong>最小化损失函数</strong>来学习参数   </p>
<p>  $\mathbf{w}^<em>,\mathbf{b}^</em>&#x3D;\arg\min\limits_{\mathbf{w},b}\ell(\mathbf{X},\mathbf{y},\mathbf{w},b)$</p>
</li>
</ul>
<p><strong>均方误差</strong>（Mean Squared Error, <strong>MSE</strong>）是一种常用的损失函数，用于衡量预测值与真实值之间的差异：</p>
<p>$\text{MSE} &#x3D; \frac{1}{n}\sum\limits_{i&#x3D;1}^n(y_i-\hat{y})^2$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>



<hr>
<h2 id="基础优化方法"><a href="#基础优化方法" class="headerlink" title="基础优化方法"></a>基础优化方法</h2><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>当一个模型<strong>没有显式解</strong>时，如何操作？</p>
<ol>
<li><p>挑选一个初始值$\mathbf{w}_0$</p>
</li>
<li><p>重复迭代参数 t &#x3D; 1, 2, 3</p>
<p> $\mathbf{w}<em>t&#x3D; \mathbf{w}</em>{t-1} -\eta \frac{\partial \ell}{\partial \mathbf{w}_{t-1}}$</p>
<p> $\frac{\partial \ell}{\partial \mathbf{w}<em>{t-1}}$：损失函数$\ell$关于$\mathbf{w}</em>{t-1}$的梯度</p>
<ul>
<li>沿梯度方向将增加损失函数值</li>
<li>学习率$\eta$：<strong>步长</strong>的<strong>超参数（需要人为指定的值）</strong>。学习率<strong>不能太小，也不能太大</strong>。</li>
</ul>
</li>
</ol>
<hr>
<p>在实际中，很少直接使用梯度下降，最长使用的形式是<strong>小批量随机梯度下降</strong>。</p>
<ul>
<li><p>在整个训练集上算梯度成本高昂</p>
<p>  一个深度神经网络模型可能需要数分钟至数小时</p>
</li>
<li><p>可以随机采样 b 个样本$i_1, i_2, …, i_b$来<strong>近似损失</strong><br>  $\frac{1}{b}\sum\limits_{i\in I_b}\ell(\mathbf{x}_i, y_i, \mathbf{w})$</p>
</li>
</ul>
<p>b是<strong>批量大小</strong>，另一个重要的超参数。</p>
<hr>
<ul>
<li>梯度下降通过不断沿着<strong>反梯度方向</strong>更新参数求解</li>
<li><strong>小批量随机梯度下降</strong>是深度学习<strong>默认</strong>的求解算法</li>
<li>两个重要的<strong>超参数</strong>是<strong>批量大小</strong>和<strong>学习率</strong></li>
</ul>
<hr>
<h2 id="pytorch实现"><a href="#pytorch实现" class="headerlink" title="pytorch实现"></a>pytorch实现</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> random
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data

<span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""生成 y = Xw + b + 噪音。"""</span>
    <span class="token comment"># 从均值为0，标准差为1的正态分布中随机采样 形状为(num_examples, len(w)) 的张量x</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># torch.matmul：进行矩阵乘法</span>
    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    <span class="token comment"># 添加噪音，从均值为0，标准差为0.01的正态分布中随机采样</span>
    y <span class="token operator">+=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># -1：表示根据张量的总元素数量自动确定有多少行</span>
    <span class="token comment"># 1：表示每行的大小为 1。</span>
    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


true_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
true_b <span class="token operator">=</span> <span class="token number">4.2</span>
features<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="调用框架中现有的api来读取数据"><a href="#调用框架中现有的api来读取数据" class="headerlink" title="调用框架中现有的api来读取数据"></a>调用框架中现有的api来读取数据</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_array</span><span class="token punctuation">(</span>data_arrays<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""构造一个pytorch数据迭代器"""</span>
    dataset <span class="token operator">=</span> data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span><span class="token operator">*</span>data_arrays<span class="token punctuation">)</span>
    <span class="token comment"># 按batch_size来随机读取样本</span>
    <span class="token keyword">return</span> data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>is_train<span class="token punctuation">)</span>


batch_size <span class="token operator">=</span> <span class="token number">10</span>
data_iter <span class="token operator">=</span> load_array<span class="token punctuation">(</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>

<span class="token comment"># iter() 将可迭代对象data_iter转换为迭代器对象，</span>
<span class="token comment"># next() 函数从迭代器中获取下一个元素。</span>
<span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="使用框架的预定义好的层"><a href="#使用框架的预定义好的层" class="headerlink" title="使用框架的预定义好的层"></a>使用框架的预定义好的层</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token comment"># Linear 线性回归（全连接层），输入维度是2，输出是1</span>
<span class="token comment"># Sequential 看作 神经网络层的list</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="初始化模型参数"><a href="#初始化模型参数" class="headerlink" title="初始化模型参数"></a>初始化模型参数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># normal_ 对权重参数的数据进行正态分布初始化，均值为 0，标准差为 0.01</span>
net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>
<span class="token comment"># bias 偏差</span>
net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="计算均方误差使用MSELoss类"><a href="#计算均方误差使用MSELoss类" class="headerlink" title="计算均方误差使用MSELoss类"></a>计算均方误差使用<code>MSELoss</code>类</h3><p>$\text{MSE} &#x3D; \frac{1}{n}\sum\limits_{i&#x3D;1}^n(y_i-\hat{y})^2$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<h3 id="实例化SGD实例"><a href="#实例化SGD实例" class="headerlink" title="实例化SGD实例"></a>实例化SGD实例</h3><p>随机梯度下降（SGD, Stochastic Gradient Descent）</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># torch.optim.SGD是一个优化器类</span>
trainer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<hr>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 遍历训练数据集的批次</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        <span class="token comment"># 计算预测值，计算预测值与真实标签之间的损失</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token comment"># 梯度清零</span>
        trainer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 反向传播，计算损失函数关于模型参数的梯度s</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 根据计算得到的梯度值和SGD的规则 更新模型参数</span>
        trainer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 对 所有训练数据 进行预测，计算损失值</span>
    l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'epoch </span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">&#125;</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">&#123;</span>l<span class="token punctuation">:</span><span class="token format-spec">f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h1 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h1><p>Softmax回归其实是一个<strong>分类</strong>问题。</p>
<ul>
<li>回归估计一个<strong>连续值</strong><ul>
<li>跟真实值的区别作为损失</li>
</ul>
</li>
<li>分类预测一个<strong>离散类别</strong><ul>
<li>通常多个输出</li>
<li>输出i是预测为第i类的置信度</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h2><p>$softmax(o)&#x3D;\hat{y}$</p>
<p>$softmax(o)_i &#x3D; \hat{y}_i&#x3D;\frac{\exp(o_i)}{\sum_j\exp(o_j)}$</p>
<ul>
<li>$softmax(o)_i$ 是模型输出 <code>o</code> 经过 softmax 函数后的概率分布的第 <code>i</code> 个元素。</li>
<li>$\sum_j\exp(o_j)$：<strong>所有</strong>向量指数的和</li>
</ul>
<p>使用Softmax函数得到<strong>每个类的预测置信度</strong>。</p>
<hr>
<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>交叉熵常用来衡量两个概率的区别：$H(p,q)&#x3D;\sum\limits_i -p_i\log (q_i)$</p>
<p>将它作为损失：<br>    $\ell(y,\hat{y})&#x3D; -\sum\limits_i y_i\log \hat{y}_i &#x3D; -\log \hat{y}_y$</p>
<p>将每个类别的真实标签的概率 $y_i$ 乘以预测概率 $\hat{y}_i$ 的负对数，并将所有类别的结果求和。交叉熵衡量了预测概率分布 $\hat{y}_i$  在真实概率分布 $y_i$ 上的<strong>不确定性和差异</strong>。</p>
<p>交叉熵损失函数对模型输出 <code>o</code> 求梯度，即<strong>真实概率和预测概率的区别</strong><br>    $\partial_{o_i}\ell(y, \hat{y}) &#x3D; softmax(o)_i - y_i$</p>
<hr>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="均方损失-L-2-Loss"><a href="#均方损失-L-2-Loss" class="headerlink" title="均方损失 $L_2$ Loss"></a>均方损失 $L_2$ Loss</h3><p>$\ell(y,y^{‘})&#x3D;\frac{1}{2}(y-y^{‘})^2$</p>
<hr>
<h3 id="绝对值损失-L-1-Loss"><a href="#绝对值损失-L-1-Loss" class="headerlink" title="绝对值损失 $L_1$ Loss"></a>绝对值损失 $L_1$ Loss</h3><p>$\ell(y, y^{‘})&#x3D;|y-y^{‘}|$</p>
<p>优化到末期时，就不那么稳定</p>
<hr>
<h2 id="Softmax回归的从零开始实现"><a href="#Softmax回归的从零开始实现" class="headerlink" title="Softmax回归的从零开始实现"></a>Softmax回归的从零开始实现</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> IPython <span class="token keyword">import</span> display

<span class="token keyword">def</span> <span class="token function">get_dataloader_workers</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""使用4个进程来读取的数据"""</span>
    <span class="token keyword">return</span> <span class="token number">4</span>


<span class="token keyword">def</span> <span class="token function">load_data_fashion_mnist</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> resize<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""下载Fashion-MNIST数据集，然后将其加载到内存中"""</span>
    trans <span class="token operator">=</span> <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token comment"># 接受一个可选参数resize，用来将图像大小调整为另一种形状。</span>
    <span class="token keyword">if</span> resize<span class="token punctuation">:</span>
        trans<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>resize<span class="token punctuation">)</span><span class="token punctuation">)</span>
    trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>trans<span class="token punctuation">)</span>
    mnist_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"../data"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>trans<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    mnist_test <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>
        root<span class="token operator">=</span><span class="token string">"../data"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>trans<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 这个函数返回训练集和验证集的数据迭代器。</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                            num_workers<span class="token operator">=</span>get_dataloader_workers<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_test<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                            num_workers<span class="token operator">=</span>get_dataloader_workers<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    
batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span> test_iter <span class="token operator">=</span> load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li>softmax的输入需要是一个向量，展平每个图像，将它们视为长度为784（1*28*28）的向量。</li>
<li>因为我们的数据集有10个类别，所以网络输出维度为10</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">num_inputs <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">*</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span>
num_outputs <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 从均值为0，标准差为0.01的正态分布中随机采样</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_outputs<span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="实现Softmax回归模型"><a href="#实现Softmax回归模型" class="headerlink" title="实现Softmax回归模型"></a>实现Softmax回归模型</h3><p>对于一个矩阵来说，就是<strong>按行</strong>来做softmax。</p>
<p>$softmax(X)<em>{ij}&#x3D;\frac{\exp (X</em>{ij})}{\sum_{k}\exp (X_{ik})}$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 对每个元素做指数计算</span>
    X_exp <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># 按照维度为1（行）进行求和</span>
    partition <span class="token operator">=</span> X_exp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> X_exp <span class="token operator">/</span> partition  <span class="token comment"># 应用了广播机制</span>

<span class="token keyword">def</span> <span class="token function">net</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># torch.matmul：进行矩阵乘法</span>
    <span class="token comment"># -1：表示根据张量的总元素数量自动确定有多少行</span>
    <span class="token comment"># 最终得到1个 所有的元素值>0，行和为1的输出</span>
    <span class="token keyword">return</span> softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="实现交叉熵损失函数"><a href="#实现交叉熵损失函数" class="headerlink" title="实现交叉熵损失函数"></a>实现交叉熵损失函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># log实际是ln</span>
    <span class="token comment"># len() 能获取矩阵的行数</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_hat<span class="token punctuation">[</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="将预测类别与真实y元素进行比较"><a href="#将预测类别与真实y元素进行比较" class="headerlink" title="将预测类别与真实y元素进行比较"></a>将预测类别与真实<code>y</code>元素进行比较</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算预测正确的数量"""</span>
    <span class="token comment"># y_hat 是一个二维张量且有多个列（即表示多类别分类任务的预测结果）</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span> <span class="token keyword">and</span> y_hat<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
        <span class="token comment"># argmax 函数用于在给定轴上找到张量中最大元素的索引</span>
        <span class="token comment"># 使用 argmax 函数沿着列的维度（每行）计算出每个样本的预测标签</span>
        y_hat <span class="token operator">=</span> y_hat<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># y.dtype 获取 y 张量的数据类型，使用 y_hat.type(y.dtype) 将 y_hat 的数据类型转换为与 y 相同的类型。</span>
    <span class="token builtin">cmp</span> <span class="token operator">=</span> y_hat<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token operator">==</span> y
    <span class="token comment"># 计算布尔张量 cmp 中值为 True 的元素的数量，并将结果转换为浮点数。返回预测正确的数量。</span>
    <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token builtin">cmp</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="评估准确率"><a href="#评估准确率" class="headerlink" title="评估准确率"></a>评估准确率</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Accumulator</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""For accumulating sums over `n` variables."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用列表推导式创建了一个名为 data 的列表，初始化为长度为 n 的全零列表。</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span> <span class="token operator">*</span> n

    <span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># zip 函数将 data 列表与参数 args 逐个配对，并使用列表推导式将它们相加</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span>a <span class="token operator">+</span> <span class="token builtin">float</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token keyword">for</span> a<span class="token punctuation">,</span> b <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将 data 列表的每个元素都设置为 0.0。</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> data_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算在指定数据集上模型的精度"""</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将模型设置为评估模式（不计算梯度）</span>
        net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 正确预测数、预测总数</span>
    metric <span class="token operator">=</span> Accumulator<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        <span class="token comment"># accuracy 预测正确的个数</span>
        <span class="token comment"># `numel()`函数：访问张量中元素的总数。</span>
        metric<span class="token punctuation">.</span>add<span class="token punctuation">(</span>accuracy<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> metric<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> metric<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 

<span class="token comment"># 未经训练时的准确率</span>
evaluate_accuracy<span class="token punctuation">(</span>net<span class="token punctuation">,</span> test_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="训练的一个迭代周期"><a href="#训练的一个迭代周期" class="headerlink" title="训练的一个迭代周期"></a>训练的一个迭代周期</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 训练模型一个迭代周期</span>
<span class="token keyword">def</span> <span class="token function">train_epoch</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> updater<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
        net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    metric <span class="token operator">=</span> Accumulator<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
        y_hat <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token comment"># 如果updater是pytorch的optimizer</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>updater<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 使用pytorch内置的优化器，将梯度设为0</span>
            updater<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 计算梯度</span>
            l<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 对参数进行一次更新</span>
            updater<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            updater<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 训练损失总和，正确的分类数，样本数 放入累加器</span>
        metric<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># loss的累加 / 样本数，分类正确的样本数 / 样本数（训练损失和训练精度）</span>
    <span class="token keyword">return</span> metric<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> metric<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> metric<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> metric<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="定义一个在动画中绘制数据的类"><a href="#定义一个在动画中绘制数据的类" class="headerlink" title="定义一个在动画中绘制数据的类"></a>定义一个在动画中绘制数据的类</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> matplotlib_inline<span class="token punctuation">.</span>backend_inline <span class="token keyword">import</span> set_matplotlib_formats


<span class="token keyword">class</span> <span class="token class-name">Animator</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""在动画中绘制数据"""</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> xlabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> ylabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xlim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> ylim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> yscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>
                 fmts<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">,</span> <span class="token string">'m--'</span><span class="token punctuation">,</span> <span class="token string">'g-.'</span><span class="token punctuation">,</span> <span class="token string">'r:'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 增量地绘制多条线</span>
        <span class="token keyword">if</span> legend <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            legend <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        set_matplotlib_formats<span class="token punctuation">(</span><span class="token string">'svg'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fig<span class="token punctuation">,</span> self<span class="token punctuation">.</span>axes <span class="token operator">=</span> d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token punctuation">,</span> ncols<span class="token punctuation">,</span> figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>
        <span class="token keyword">if</span> nrows <span class="token operator">*</span> ncols <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>axes <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>axes<span class="token punctuation">,</span> <span class="token punctuation">]</span>
        <span class="token comment"># 使用lambda函数捕获参数</span>
        self<span class="token punctuation">.</span>config_axes <span class="token operator">=</span> <span class="token keyword">lambda</span><span class="token punctuation">:</span> d2l<span class="token punctuation">.</span>set_axes<span class="token punctuation">(</span>self<span class="token punctuation">.</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> xlabel<span class="token punctuation">,</span> ylabel<span class="token punctuation">,</span> xlim<span class="token punctuation">,</span> ylim<span class="token punctuation">,</span> xscale<span class="token punctuation">,</span> yscale<span class="token punctuation">,</span> legend<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>fmts <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> fmts

    <span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 向图表中添加多个数据点</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token string">"__len__"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            y <span class="token operator">=</span> <span class="token punctuation">[</span>y<span class="token punctuation">]</span>
        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">"__len__"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token operator">*</span> n
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>X<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> a <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> b <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>Y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>fmts<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>axes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>config_axes<span class="token punctuation">(</span><span class="token punctuation">)</span>
        display<span class="token punctuation">.</span>display<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fig<span class="token punctuation">)</span>
        display<span class="token punctuation">.</span>clear_output<span class="token punctuation">(</span>wait<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="训练函数"><a href="#训练函数" class="headerlink" title="训练函数"></a>训练函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> updater<span class="token punctuation">)</span><span class="token punctuation">:</span>
    animator <span class="token operator">=</span> Animator<span class="token punctuation">(</span>xlabel<span class="token operator">=</span><span class="token string">'epoch'</span><span class="token punctuation">,</span> xlim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">]</span><span class="token punctuation">,</span> ylim<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        legend<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'train loss'</span><span class="token punctuation">,</span> <span class="token string">'train acc'</span><span class="token punctuation">,</span> <span class="token string">'test acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_metrics <span class="token operator">=</span> train_epoch<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> updater<span class="token punctuation">)</span>
        test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>net<span class="token punctuation">,</span> test_iter<span class="token punctuation">)</span>
        <span class="token comment"># 将当前训练轮次的指标（训练损失、训练准确率和测试准确率）添加到 animator 对象中，用于可视化展示。</span>
        <span class="token comment"># 如果 train_metrics 的值是 (0.2, 0.8)，而 test_acc 的值是 0.75，那么 train_metrics + (test_acc,) 的结果将是 (0.2, 0.8, 0.75)。</span>
        animator<span class="token punctuation">.</span>add<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> train_metrics <span class="token operator">+</span> <span class="token punctuation">(</span>test_acc<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_loss<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> train_metrics
    <span class="token comment"># 检查最后一轮训练的损失是否小于 0.5，如果不满足条件，则抛出异常。</span>
    <span class="token keyword">assert</span> train_loss <span class="token operator">&lt;</span> <span class="token number">0.5</span><span class="token punctuation">,</span> train_loss
    <span class="token comment"># 检查最后一轮训练的准确率是否在 0.7 到 1 之间，如果不满足条件，则抛出异常。</span>
    <span class="token keyword">assert</span> <span class="token number">1</span> <span class="token operator">>=</span> train_acc <span class="token operator">></span> <span class="token number">0.7</span><span class="token punctuation">,</span> train_acc
    <span class="token comment"># 检查最后一轮测试的准确率是否在 0.7 到 1 之间，如果不满足条件，则抛出异常。</span>
    <span class="token keyword">assert</span> <span class="token number">1</span> <span class="token operator">>=</span> test_acc <span class="token operator">></span> <span class="token number">0.7</span><span class="token punctuation">,</span> test_acc
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="小批量随机梯度下降来优化模型的损失函数"><a href="#小批量随机梯度下降来优化模型的损失函数" class="headerlink" title="小批量随机梯度下降来优化模型的损失函数"></a>小批量随机梯度下降来优化模型的损失函数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sgd</span><span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""随机梯度下降（Stochastic Gradient Descent）
    小批量梯度下降"""</span>
    <span class="token comment"># 更新时不参与梯度计算</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
            param <span class="token operator">-=</span> lr <span class="token operator">*</span> param<span class="token punctuation">.</span>grad <span class="token operator">/</span> batch_size
            param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>


lr <span class="token operator">=</span> <span class="token number">0.1</span>


<span class="token keyword">def</span> <span class="token function">updater</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="训练10个迭代周期，对图像进行分类预测"><a href="#训练10个迭代周期，对图像进行分类预测" class="headerlink" title="训练10个迭代周期，对图像进行分类预测"></a>训练10个迭代周期，对图像进行分类预测</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_epochs <span class="token operator">=</span> <span class="token number">10</span>
train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> cross_entropy<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> updater<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">get_fashion_mnist_labels</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""返回Fashion-MNIST数据集的文本标签"""</span>
    text_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'t-shirt'</span><span class="token punctuation">,</span> <span class="token string">'trouser'</span><span class="token punctuation">,</span> <span class="token string">'pullover'</span><span class="token punctuation">,</span> <span class="token string">'dress'</span><span class="token punctuation">,</span> <span class="token string">'coat'</span><span class="token punctuation">,</span>
                   <span class="token string">'sandal'</span><span class="token punctuation">,</span> <span class="token string">'shirt'</span><span class="token punctuation">,</span> <span class="token string">'sneaker'</span><span class="token punctuation">,</span> <span class="token string">'bag'</span><span class="token punctuation">,</span> <span class="token string">'ankle boot'</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>text_labels<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> labels<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">show_images</span><span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> num_rows<span class="token punctuation">,</span> num_cols<span class="token punctuation">,</span> titles<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""绘制图像列表"""</span>
    fig_size <span class="token operator">=</span> <span class="token punctuation">(</span>num_cols <span class="token operator">*</span> scale<span class="token punctuation">,</span> num_rows <span class="token operator">*</span> scale<span class="token punctuation">)</span>
    _<span class="token punctuation">,</span> axes <span class="token operator">=</span> d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>num_rows<span class="token punctuation">,</span> num_cols<span class="token punctuation">,</span> figsize<span class="token operator">=</span>fig_size<span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax<span class="token punctuation">,</span> img<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>axes<span class="token punctuation">,</span> imgs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>is_tensor<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 图片张量</span>
            ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># PIL图片</span>
            ax<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_xaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_yaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> titles<span class="token punctuation">:</span>
            ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>titles<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> axes

<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> test_iter<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""预测标签"""</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_iter<span class="token punctuation">:</span>
        <span class="token keyword">break</span>
    trues <span class="token operator">=</span> get_fashion_mnist_labels<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    preds <span class="token operator">=</span> get_fashion_mnist_labels<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    titles <span class="token operator">=</span> <span class="token punctuation">[</span>true <span class="token operator">+</span> <span class="token string">'\n'</span> <span class="token operator">+</span> pred <span class="token keyword">for</span> true<span class="token punctuation">,</span> pred <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>trues<span class="token punctuation">,</span> preds<span class="token punctuation">)</span><span class="token punctuation">]</span>
    show_images<span class="token punctuation">(</span>
        X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>n<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> titles<span class="token operator">=</span>titles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>n<span class="token punctuation">]</span><span class="token punctuation">)</span>


predict<span class="token punctuation">(</span>net<span class="token punctuation">,</span> test_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h1 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h1><h2 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h2><p>给定输入$\mathbf{x}$，权重$\mathbf{w}$，偏移$b$，感知机输出：</p>
<p>$o&#x3D;\sigma(\langle\mathbf{w},\mathbf{x}\rangle+b)$</p>
<p>$\sigma(x)&#x3D;\begin{cases}1 \ \ \text{if}\ x &gt; 0\0 \ \ \text{otherwise}\end{cases}$</p>
<p><strong>感知机</strong>其实就是<strong>二分类</strong>的问题。</p>
<ul>
<li>和线性回归相比，线性回归输出<strong>实数</strong>。</li>
<li>和Softmax回归相比，Softmax是<strong>多分类</strong>。</li>
</ul>
<hr>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><h2 id="模型容量"><a href="#模型容量" class="headerlink" title="模型容量"></a>模型容量</h2><p>模型容量指的是<strong>拟合各种函数的能力</strong>。</p>
<ul>
<li>低容量的模型难以拟合训练数据</li>
<li>高容量的模型可以记住所有的训练数据。</li>
</ul>
<hr>
<h1 id="网络中的网络-NiN"><a href="#网络中的网络-NiN" class="headerlink" title="网络中的网络 NiN"></a>网络中的网络 NiN</h1><h2 id="全连接层的问题"><a href="#全连接层的问题" class="headerlink" title="全连接层的问题"></a>全连接层的问题</h2><p>卷积层只需要较少的参数，但卷积层之后的第一个全连接层需要的<strong>参数量很大</strong>。</p>
<ul>
<li>卷积层的参数量： $c_i\times c_o \times k^2$ （输入通道数 x 输出通道数 x <strong>卷积核的</strong>高 x <strong>卷积核的</strong>宽）</li>
<li>全连接层的参数量：$c_i\times w_i \times h_i \times c_o \times w_o \times h_i$  （输入通道数 x 输入宽度 x 输入高度 x 输出通道数 x 输出宽度 x 输出高度）</li>
</ul>
<p>参数量大，<strong>会占用很多内存、计算带宽、容易过拟合</strong>。</p>
<hr>
<h2 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h2><p>1个卷积层后跟2个<strong>1 * 1的卷积层，对每个像素增加了非线性</strong>：</p>
<ul>
<li>步幅1，无填充，输出形状跟卷积层输出一样</li>
<li>起到全连接层的作用</li>
</ul>
<hr>
<h2 id="NiN架构"><a href="#NiN架构" class="headerlink" title="NiN架构"></a>NiN架构</h2><ul>
<li>无全连接层</li>
<li>交替使用NiN块和步幅为2的最大池化层，<strong>逐步减小宽高、增大通道数</strong>。</li>
<li>最后使用<strong>全局平均池化层</strong>得到输出，不容易过拟合，更少的参数个数。<ul>
<li>输入通道数是类别数</li>
</ul>
</li>
</ul>
<hr>
<h1 id="含并行连结的网络-GoogLeNet-Inception-V3"><a href="#含并行连结的网络-GoogLeNet-Inception-V3" class="headerlink" title="含并行连结的网络 GoogLeNet &#x2F; Inception V3"></a>含并行连结的网络 GoogLeNet &#x2F; Inception V3</h1><p><strong>Inception块用4条有不同超参数的卷积层和池化层的路来抽取不同的信息</strong>，它的一个主要优点是模型参数小，计算复杂度低。</p>
<p><img src="https://s2.loli.net/2024/02/22/QPhN9cY6Gg2yufK.png" alt="image-20240222140852981"></p>
<p>GoogLeNet使用了9个lnception块，是<strong>第一个达到上百层的网络</strong>，后续有一系列改进。</p>
<hr>
<h1 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h1><p>损失出现在最后，后面的层训练较快。</p>
<p>数据在最底部</p>
<ul>
<li>底部的层训练较慢</li>
<li>底部层一变化，所有都得跟着变</li>
<li>最后的那些层需要重新学习多次</li>
<li>导致收敛变慢</li>
</ul>
<p>我们可以在学习底部层的时候避免变化顶部层吗?</p>
<hr>
<ul>
<li><p>固定小批量B里的样本x的均值</p>
<p>  $\mu_B&#x3D;\frac {1}{|B|}\sum\limits_{x\in B}x_i$</p>
</li>
<li><p>固定小批量B里的样本x的方差</p>
<p>  $\sigma^2_B&#x3D;\frac{1}{|B|}\sum\limits_{i\in B}(x_i-\mu_B)^2+\epsilon$</p>
<p>  $\epsilon$是为了<strong>防止方差为0</strong>的一个很小的数。</p>
</li>
</ul>
<p>批量归一化就是通过<strong>可学习的参数</strong>$\gamma、\beta$得到的结果：</p>
<p>$x_{i+1}&#x3D;\gamma\frac{x_i-\mu_B}{\sigma_B}+\beta$</p>
<hr>
<h2 id="批量归一化层"><a href="#批量归一化层" class="headerlink" title="批量归一化层"></a>批量归一化层</h2><ul>
<li>含有可学习的参数为$\gamma$和$\beta$</li>
<li>作用范围：<ul>
<li>全连接层和卷积层<strong>输出上</strong>，激活函数前</li>
<li>全连接层和卷积层<strong>输入上</strong></li>
</ul>
</li>
<li>对全连接层，作用在<strong>特征</strong>维</li>
<li>对于卷积层，作用在<strong>通道</strong>维</li>
</ul>
<hr>
<h2 id="批量归一化在做什么"><a href="#批量归一化在做什么" class="headerlink" title="批量归一化在做什么"></a>批量归一化在做什么</h2><p>后续有论文指出它<strong>可能</strong>就是通过在每个小批量里<strong>加入噪音来控制模型复杂度</strong>，因此没必要跟丢弃法混合使用。</p>
<p>$x_{i+1}&#x3D;\gamma\frac{x_i-\hat{\mu}_B}{\hat{\sigma}_B}+\beta$</p>
<p>把$\hat{\mu}_B$和$\hat{\sigma}_B$看作<strong>随机偏移</strong>和<strong>随机缩放</strong>。</p>
<p>批量归一化固定小批量中的均值和方差，然后学习出适合的偏移和缩放。<strong>可以加速收敛速度，但一般不改变模型精度</strong>。</p>
<hr>
<h1 id="残差网络-ResNet"><a href="#残差网络-ResNet" class="headerlink" title="残差网络 ResNet"></a>残差网络 ResNet</h1><h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h2><ul>
<li>串联一个层改变函数类，希望能扩大函数类。</li>
<li>残差块加入快速通道，来得到$f(x)&#x3D;x+g(x)$的结构</li>
</ul>
<p><img src="https://s2.loli.net/2024/02/23/6kwuFPxZlWJeQT5.png" alt="image-20240223134806237"></p>
<p>有很多调整变形的排列组合。</p>
<p>有两种残差块：</p>
<ol>
<li>高宽减半、通道数翻倍的残差块（步幅stride&#x3D;2）</li>
<li>接多个高宽不变的残差块（步幅stride&#x3D;1）</li>
</ol>
<p>残差块<strong>使得很深的网络更加容易训练</strong>，甚至可以训练一千层的网络。</p>
<hr>
<h1 id="数据增广"><a href="#数据增广" class="headerlink" title="数据增广"></a>数据增广</h1><p>数据增强就是在一个已有的数据集中，通过变形数据，使得数据集有更多的多样性，模型繁华性能更好。例如：</p>
<ol>
<li>在语言里加入各种不同的背景噪音</li>
<li>改变图片的形状和颜色</li>
</ol>
<p>常见的图片的数据增强的形式：</p>
<ol>
<li>翻转</li>
<li>切割</li>
<li>变色</li>
</ol>
<hr>
<h1 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h1><ul>
<li>微调通过使用在大数据上得到的预训练好的模型，来初始化模型权重，来完成提升精度。</li>
<li>预训练模型质量很重要。</li>
<li>微调通常速度更快、精度更高。</li>
</ul>
<hr>
<h1 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h1><ul>
<li>时序模型中，<strong>当前数据跟之前观察到的数据相关</strong></li>
<li>自回归模型<strong>使用自身过去数据来预测未来</strong></li>
<li>马尔科夫模型假设当前只跟最近少数数据相关，从而简化模型</li>
<li>潜变量模型使用潜变量来概括历史信息</li>
</ul>
<p>​		</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/01/23/%E5%9B%BE%E5%BA%8A/" rel="prev" title="Spring Boot">
                  <i class="fa fa-angle-left"></i> Spring Boot
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/04/17/PriorityQueue%E4%B8%8EComparator/" rel="next" title="PriorityQueue与Comparator">
                  PriorityQueue与Comparator <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Hunter</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Hunter1023/Hunter1023.github.io","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
